# 유예원
# 🔥 Java Stream Performance Test
Java Stream 사용 시 발생할 수 있는 성능 이슈를 직접 실험하고 비교하기 위한 예제 프로젝트입니다.  
특히 다음 두 가지 상황에 대해 코드 및 실행 속도를 비교했습니다.

- Parallel Stream 사용 시 오버헤드 문제
- Intermediate Operation을 과도하게 사용했을 때의 영향
  <br><br>
## 1번 병렬 스트림 실행 속도 측정
### ❓ 실행 목적
Parallel Stream이 항상 성능 향상을 보장하지 않으며,  
작은 데이터셋이나 가벼운 연산에서는 오히려 오버헤드가 발생할 수 있음을 확인합니다.
<br>
- 📝 TimeTest.java
<br>

### 1. 테스트 결과
<img width="788" height="163" alt="image" src="https://github.com/user-attachments/assets/8017c2ae-9cc3-4110-9196-45a41a403ae3" />

<br>

### ✅ 작은 데이터셋에서는 다수의 스레드를 생성하는 비용이 연산 비용보다 큼
<br>

### Why?


- 병렬 스트림은 내부적으로 ForkJoinPool을 사용

- 스레드 분할, 작업 분배, 병합 비용이 발생

- 하지만 연산이 너무 가볍고 데이터가 적음 → 오버헤드가 더 큼
<br>
➡️ 여러 스레드가 동원되지만 성능 이득은 없음! 병렬로 나눌 필요가 없는 일을 굳이 나눴다

<br><br>
## 2번 중간 연산과다 속도 측정
### ❓ 실행 목적
Stream 파이프라인에서 Intermediate Operation을 과도하게 사용할 경우
성능과 가독성에 어떤 영향을 주는지 비교합니다.
<br>
- 📝StreamPerformanceTest.java
<br>

### 2. 테스트 결과
<img width="793" height="178" alt="image" src="https://github.com/user-attachments/assets/e25cf526-ca01-441a-9ee2-e9cd5ba742bc" />

<br>

### ✅ filter 연산 통합으로 Stream pipeline 단순화

### Why?

- filter를 여러 번 사용 → 연산 단계 증가 → 스트림 파이프라인이 불필요하게 길어짐

- 대량 데이터 처리 시 미세한 성능 저하
<br>
➡️ 결과는 같지만 가독성 저하, 대량 데이터에서는 성능 저하

<br>
# 권순재
# 🏃 Java Stream Performance Test

## 🙅‍♂️ Java Stream에서 자주 하는 실수 7가지
1. collect(), forEach(), reduce() 등과 같은 Terminal Operation을 쓰지 않는 경우가 있다..
2. 데이터 구조를 바꿀 때 예상치 못한 결과가 나올 수도 있다.
3. 병렬로 처리하는 것이 항상 성능 향상에 좋은 것은 아니다. (작은 프로젝트에서는 성능을 떨어뜨릴 수도 있다.)
4. filter()나 map() 같은 중간 연산자들을 너무 많이 주렁주렁 연결하면 성능 저하(오버헤드) 가 발생할 수 있다.
5. findFirst()나 reduce() 같은 연산은 결과로 Optional 객체를 반환하는데, 이를 제대로 처리하지 않는 것이다
6. 병렬 스트림을 사용할 때 공유 변수를 동시에 바꾸면 race condition이 발생하거나 결과값이 뒤죽박죽이 될 수 있다.
7. 새로운 스트림을 리턴하는 중간 연산(Intermediate)과, 실제로 결과를 도출해 내는 최종 연산(Terminal)의 차이를 혼동하는 것이다.

## 소개
실행 속도에 영향을 주는 3,4번 실수를 구현 해 볼 것이다.

### 1. 큰 데이터와 작은 데이터에서 순차처리와 병렬처리의 실행 속도 비교(StreamLab.java)
1. **데이터 크기**: 작은 데이터: 1,000개, 큰 데이터: 10,000,000개
2. **연산 작업**: 리스트의 각 숫자를 제곱하여 다시 리스트에 넣기

### 결과 분석 (Result)

| 데이터 크기 | 처리 방식 (Method) | 소요 시간 (측정마다 다르게 나옴) |
|:---:|:---:|:---|
| **작은 데이터** | **Stream (Sequential)** | 1ms |
|  | **Stream (Parallel)** | 12ms | 
| **큰 데이터** | **Stream (Sequential)** | 445ms | 
| | **Stream (Parallel)** | 336ms |
- 큰 데이터를 처리할 때에는 병렬처리 방식이 더 빠르지만 작은 데이터를 처리할 때에는 순차처리 방식이 더 빠르다.

<br>

**작은 데이터에서 병렬처리가 느린 이유**
  > 병렬처리를 하기 위해서는 새로운 스레드를 할당하고, CPU가 여러 스레드를 왔다 갔다 하는 context switching 비용이 발생한다. 데이터가 작은 경우 데이터를 순차적으로 처리하는 비용보다 context switch하는 비용이 더 크기 때문에 느리게 나온다

### 2. filter()나 map() 같은 중간 연산자들을 많이 사용했을 때의 성능 비교 (StreamLab2.java)

### 결과 분석 (Result)

| 처리 방식 (Method) | 소요 시간 (측정마다 다르게 나옴) |
|:---:|:---|
| **중간 연산자가 많을 때** | 17ms |
| **중간 연산자가 적을 때**  | 2ms |
- 중간 연산자가 적을 때 더 빨랐다.

<br>

**중간 연산자가 많을 때 더 느린 이유**
  1. 연산자를 사용할 때마다 새로운 스트림 객체가 힙 메모리에 계속 만들어진다. 객체를 생성하며 드는 비용으로 인해 속도가 느려진다.
  2. 연산자가 나뉘어 있으면 데이터가 지나갈 때마다 함수를 호출해야한다. 즉, 함수 호출 비용이 든다.

<br>
# 서가영
### 1️⃣ Parallel Stream Overhead 
- Parrllel Stream : 각각의 스레드에서 스트림을 처리할 수 있도록 스트림 요소를 여러 청크로 분할한 것

#### 1. 가정한 문제 상황
   - 소규모 데이터를 처리하는 경우에는 순차 스트림이 성능 면에서 효율적이다.

#### 2. 문제 상황이 발생하는 이유
   - 스레드를 생성하고 할당하는 비용이 더 많이 들기 때문이다.

#### 3. 검증 방법
   - ArrayList를 생성하고 값을 할당한다.
   - sum 연산 수행을 sequential / parallel 하게 수행하여 실행 시간 오버헤드를 측정한다.
       - `System.currentTimeMillis();` 를 통해 현재 시각을 ms 단위로 기록한다.

#### 4. 실행 결과
**1. 데이터 개수 100,000,000개 (대규모 데이터)**

   - 기대한 결과 : sequential > parallel
<img width="608" height="250" alt="스크린샷 2026-01-07 170741" src="https://github.com/user-attachments/assets/2faa3824-d3fc-48d9-8050-82a183d591e6" />

  - 검증 결과와 기대한 결과가 일치함

2. 데이터 개수 500,000개 (소규모 데이터)
  - 기대한 결과 : sequential < parallel
      - '소규모 데이터에서는 병렬 스트림 사용이 오히려 비효율적일 것이다' 가정
  <img width="596" height="251" alt="스크린샷 2026-01-07 170941" src="https://github.com/user-attachments/assets/222f2701-ef69-4be7-aaef-6c556a4f7714" />


<br />


### 2️⃣ Overusing Intermediate Operations 
- 불필요한 중간 연산 체이닝은 오버헤드를 발생시켜 성능 비효율성을 초래한다.
  - Java Stream은 `filter().filter().map().map()` 처럼 코드를 작성해도 내부적으로 Stream Fusion을 통해 한 번의 순회(Loop)으로 합치기 때문에 for 문을 여러 번 돌지는 않는다.
  - 하지만 스테이지의 개수 자체가 늘기 때문에 메서드 호출 비용 등에 따른 연산 속도의 차이가 있다.
 
#### 1. 가정한 문제 상황
   - 중간 연산을 많이 사용하면 실행 시간이 증가할 것이다.

#### 2. 문제 상황이 발생하는 이유
   - 체이닝된 메서드들을 호출하는 상황은 호출 시간 등을 증가시켜 오버헤드를 발생시키기 때문이다.


#### 3. 검증 방법
   - 테스트용 ArrayList 데이터를 생성하고 값을 초기화 한다.
   - 연산이 분리된 경우 / 합쳐진 경우를 실행한다.
      - 각각의 경우는 메서드로 구현한다.
   - 각각의 연산이 영향을 미치지 않도록 중간에 GC를 실행하여 실행 상태를 분리한다.

#### 4. 실행 결과
- 데이터 개수 : 10,000,000개
<img width="637" height="256" alt="스크린샷 2026-01-07 172023" src="https://github.com/user-attachments/assets/d72e61f7-5bb7-4c13-a59a-5e7fd318983c" />

#### 5. 추가로 생각해 본 내용
- 성능상 효율적이지 않은 이유(오버헤드를 발생 시키는 원인)로 메모리 사용량도 있을 것이라 생각했다.
  - 메서드 코드 자체는 Method Area에 적재된다.
  - 메서드가 필요로 하는 인자나 반환값이 임시 Stream 객체인 경우 Heap Area에 객체를 생성한다.
  - 메서드를 실행하면서 생기는 변수 등은 Stack Area에 생성된다.

